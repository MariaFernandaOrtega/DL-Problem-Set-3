NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
Maria Fernanda Ortega Valencia and Santiago Sordo Ruz
In this project we will be teaching a neural network to translate from German to English.

This is made possible by the simple but powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence.

To improve upon this model we'll use an attention mechanism, which lets the decoder learn to focus over a specific range of the input sequence.
